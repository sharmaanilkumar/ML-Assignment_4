{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "597wDiAvGvuB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import idx2numpy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'train-images-idx3-ubyte'\n",
    "arr = idx2numpy.convert_from_file(file)\n",
    "file1 = 'train-labels-idx1-ubyte'\n",
    "arr1 = idx2numpy.convert_from_file(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 60000\n"
     ]
    }
   ],
   "source": [
    "x_train = arr\n",
    "x_train = x_train.flatten().reshape(-1,28*28)\n",
    "x_train = x_train / 255.0\n",
    "gt_indices = arr1\n",
    "train_length = len(x_train)\n",
    "print(\"Number of training examples: {:d}\".format(train_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Dimensions to be used for creating your model'''\n",
    "\n",
    "batch_size = 64  # batch size\n",
    "input_dim = 784  # input dimension\n",
    "hidden_1_dim = 256  # hidden layer 2 dimension\n",
    "output_dim = 10   # output dimension\n",
    "\n",
    "'''Other hyperparameters'''\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvVFhXNB5xrD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hImaaujc5zXg"
   },
   "outputs": [],
   "source": [
    "#creating one hot vector representation of output classification\n",
    "y_train = np.zeros((train_length, output_dim))\n",
    "# print(y.shape, gt_indices.shape)\n",
    "for i in range(train_length):\n",
    "    y_train[i,gt_indices[i]] = 1\n",
    "\n",
    "# Number of mini-batches (as integer) in one epoch\n",
    "num_minibatches = np.floor(train_length/batch_size).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W7lHWEWVaVlK",
    "outputId": "4ecb1bfc-4568-44cb-e109-57677da50eb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of mini-batches 937 and total training data used in training:59968.\n"
     ]
    }
   ],
   "source": [
    "print(\"No of mini-batches {:d} and total training data used in training:\\\n",
    "{}.\".format(num_minibatches, num_minibatches*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9HRf0Wj52cK"
   },
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "W1 = 0.2*np.random.randn(input_dim, hidden_1_dim)\n",
    "W2 = 0.2*np.random.randn(hidden_1_dim,output_dim)\n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(a):\n",
    "    return np.maximum(a,0)\n",
    "\n",
    "def grad_relu(x):\n",
    "    return 1. * (x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmZRrEVb6CJy"
   },
   "outputs": [],
   "source": [
    "# function which computes the softmax where X is vector of scores computed during forward pass\n",
    "def softmax(z):\n",
    "  \n",
    "    return np.exp(z) / np.sum(np.exp(z),axis=1,keepdims=True)\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "Gjz4yhwE6JQw",
    "outputId": "341578db-29a4-48ca-b0f8-a0343aadd24b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0, iteration: 0, Loss: 6.4924 \n",
      " Epoch: 1, iteration: 937, Loss: 0.0740 \n",
      " Epoch: 2, iteration: 1874, Loss: 0.0429 \n",
      " Epoch: 3, iteration: 2811, Loss: 0.0382 \n",
      " Epoch: 4, iteration: 3748, Loss: 0.0166 \n",
      " Epoch: 5, iteration: 4685, Loss: 0.0100 \n",
      " Epoch: 6, iteration: 5622, Loss: 0.0115 \n",
      " Epoch: 7, iteration: 6559, Loss: 0.0162 \n",
      " Epoch: 8, iteration: 7496, Loss: 0.0142 \n",
      " Epoch: 9, iteration: 8433, Loss: 0.0065 \n",
      " Epoch: 10, iteration: 9370, Loss: 0.0047 \n",
      " Epoch: 11, iteration: 10307, Loss: 0.0038 \n",
      " Epoch: 12, iteration: 11244, Loss: 0.0034 \n",
      " Epoch: 13, iteration: 12181, Loss: 0.0032 \n",
      " Epoch: 14, iteration: 13118, Loss: 0.0031 \n",
      " Epoch: 15, iteration: 14055, Loss: 0.0030 \n",
      " Epoch: 16, iteration: 14992, Loss: 0.0029 \n",
      " Epoch: 17, iteration: 15929, Loss: 0.0028 \n",
      " Epoch: 18, iteration: 16866, Loss: 0.0028 \n",
      " Epoch: 19, iteration: 17803, Loss: 0.0027 \n",
      " Epoch: 20, iteration: 18740, Loss: 0.0025 \n",
      " Epoch: 21, iteration: 19677, Loss: 0.0024 \n",
      " Epoch: 22, iteration: 20614, Loss: 0.0024 \n",
      " Epoch: 23, iteration: 21551, Loss: 0.0024 \n",
      " Epoch: 24, iteration: 22488, Loss: 0.0023 \n",
      " Epoch: 25, iteration: 23425, Loss: 0.0023 \n",
      " Epoch: 26, iteration: 24362, Loss: 0.0023 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_of_iterations = 25000\n",
    "loss_list=[]\n",
    "i_epoch = 0\n",
    "for i_iter in range(no_of_iterations):\n",
    "    \n",
    "    ''''''\n",
    "    batch_elem_idx = i_iter%num_minibatches\n",
    "    x_batchinput = x_train[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size]\n",
    "    \n",
    "   # first hidden layer implementation\n",
    "    a1 =x_batchinput@W1\n",
    "  \n",
    "    # implement Relu layer\n",
    "    h1 =relu(a1)\n",
    "    #  implement  hidden layer\n",
    "    a2 = h1@W2\n",
    "    \n",
    "    # softmax layer\n",
    "    softmax_score = softmax(a2) #enusre you have implemented the softmax function defined above\n",
    "\n",
    "    neg_log_softmax_score = -np.log(softmax_score+0.00000001) # The small number is added to avoid 0 input to log function\n",
    "    \n",
    "    # Compute and print loss\n",
    "    if i_iter%num_minibatches == 0:\n",
    "        loss = np.mean(np.diag(np.take(neg_log_softmax_score, gt_indices[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size],\\\n",
    "                                       axis=1)))\n",
    "        print(\" Epoch: {:d}, iteration: {:d}, Loss: {:6.4f} \".format(i_epoch, i_iter, loss))\n",
    "        loss_list.append(loss)\n",
    "        i_epoch += 1\n",
    "        # Each 10th epoch reduce learning rate by a factor of 10\n",
    "        if i_epoch%10 == 0:\n",
    "            learning_rate /= 10.0\n",
    "     \n",
    "    \n",
    "    \n",
    "    gradsoft = softmax_score-y_train[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size]\n",
    "    \n",
    "    # gradient w.r.t W3\n",
    "    grad_W2 = np.transpose(h1)@gradsoft\n",
    "   \n",
    "    # gradient w.r.t h1\n",
    "    grad_h1 = gradsoft@np.transpose(W2)\n",
    "    \n",
    "    # gradient w.r.t a1\n",
    "    grad_a1 = grad_h1*grad_relu(a1)\n",
    "    \n",
    "    # gradient w.r.t W1\n",
    "    grad_W1 = x_batchinput.T@grad_a1\n",
    "    \n",
    "    ################################ Update Weights Block using SGD ####################################\n",
    "    W2 -= learning_rate * grad_W2\n",
    "    W1 -= learning_rate * grad_W1\n",
    "    ####################################################################################################\n",
    "    \n",
    "#plotting the loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(loss_list)\n",
    "plt.title('Loss vs epochs')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = 't10k-images-idx3-ubyte'\n",
    "arr2 = idx2numpy.convert_from_file(file2)\n",
    "file3 = 't10k-labels-idx1-ubyte'\n",
    "arr3 = idx2numpy.convert_from_file(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading the test data from data/X_test.npy and data/y_test.npy.'''\n",
    "x_test = arr2\n",
    "x_test = x_test.flatten().reshape(-1,28*28)\n",
    "x_test = x_test / 255.0\n",
    "y_test = arr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 96.83 %\n"
     ]
    }
   ],
   "source": [
    "batch_size_test = 100 # Deliberately taken 100 so that it divides the test data size\n",
    "num_minibatches = len(y_test)/batch_size_test\n",
    "test_correct = 0\n",
    "\n",
    "'''Only forward block code and compute softmax_score .'''\n",
    "for i_iter in range(int(num_minibatches)):\n",
    "    \n",
    "    '''Get one minibatch'''\n",
    "    batch_elem_idx = i_iter%num_minibatches\n",
    "    x_batchinput = x_test[i_iter*batch_size_test:(i_iter+1)*batch_size_test]\n",
    "    \n",
    "    ######### copy only the forward pass block of your code and pass the x_batchinput to it and compute softmax_score ##########\n",
    "    a1 =x_batchinput@W1\n",
    "  \n",
    "    # implement Relu layer\n",
    "    h1 =relu(a1)\n",
    "    #  implement 2 hidden layer\n",
    "    a2 = h1@W2\n",
    "   \n",
    "    # softmax layer\n",
    "    softmax_score = softmax(a2) #Implemented the softmax function defined above\n",
    "    \n",
    "    \n",
    "    y_batchinput = y_test[i_iter*batch_size_test:(i_iter+1)*batch_size_test]\n",
    "    \n",
    "    y_pred = np.argmax(softmax_score, axis=1)\n",
    "    num_correct_i_iter = np.sum(y_pred == y_batchinput)\n",
    "    test_correct += num_correct_i_iter\n",
    "print (\"Test accuracy is {:4.2f} %\".format(test_correct/len(y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_Hidden_MLP_New.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
