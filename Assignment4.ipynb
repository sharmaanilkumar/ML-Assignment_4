{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "597wDiAvGvuB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import idx2numpy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'train-images-idx3-ubyte'\n",
    "arr = idx2numpy.convert_from_file(file)\n",
    "file1 = 'train-labels-idx1-ubyte'\n",
    "arr1 = idx2numpy.convert_from_file(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 60000\n"
     ]
    }
   ],
   "source": [
    "x_train = arr\n",
    "x_train = x_train.flatten().reshape(-1,28*28)\n",
    "x_train = x_train / 255.0\n",
    "gt_indices = arr1\n",
    "train_length = len(x_train)\n",
    "print(\"Number of training examples: {:d}\".format(train_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Dimensions to be used for creating your model'''\n",
    "\n",
    "batch_size = 64  # batch size\n",
    "input_dim = 784  # input dimension\n",
    "hidden_1_dim = 512  # hidden layer 2 dimension\n",
    "output_dim = 10   # output dimension\n",
    "\n",
    "'''Other hyperparameters'''\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvVFhXNB5xrD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hImaaujc5zXg"
   },
   "outputs": [],
   "source": [
    "#creating one hot vector representation of output classification\n",
    "y_train = np.zeros((train_length, output_dim))\n",
    "# print(y.shape, gt_indices.shape)\n",
    "for i in range(train_length):\n",
    "    y_train[i,gt_indices[i]] = 1\n",
    "\n",
    "# Number of mini-batches (as integer) in one epoch\n",
    "num_minibatches = np.floor(train_length/batch_size).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W7lHWEWVaVlK",
    "outputId": "4ecb1bfc-4568-44cb-e109-57677da50eb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of mini-batches 937 and total training data used in training:59968.\n"
     ]
    }
   ],
   "source": [
    "print(\"No of mini-batches {:d} and total training data used in training:\\\n",
    "{}.\".format(num_minibatches, num_minibatches*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9HRf0Wj52cK"
   },
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "W1 = 0.2*np.random.randn(input_dim, hidden_1_dim)\n",
    "W2 = 0.2*np.random.randn(hidden_1_dim,output_dim)\n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(a):\n",
    "    return np.maximum(a,0)\n",
    "\n",
    "def grad_relu(x):\n",
    "    return 1. * (x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmZRrEVb6CJy"
   },
   "outputs": [],
   "source": [
    "# function which computes the softmax where X is vector of scores computed during forward pass\n",
    "def softmax(z):\n",
    "  \n",
    "    return np.exp(z) / np.sum(np.exp(z),axis=1,keepdims=True)\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "Gjz4yhwE6JQw",
    "outputId": "341578db-29a4-48ca-b0f8-a0343aadd24b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0, iteration: 0, Loss: 8.0226 \n",
      " Epoch: 1, iteration: 937, Loss: 0.1081 \n",
      " Epoch: 2, iteration: 1874, Loss: 0.0274 \n",
      " Epoch: 3, iteration: 2811, Loss: 0.0187 \n",
      " Epoch: 4, iteration: 3748, Loss: 0.0117 \n",
      " Epoch: 5, iteration: 4685, Loss: 0.0073 \n",
      " Epoch: 6, iteration: 5622, Loss: 0.0064 \n",
      " Epoch: 7, iteration: 6559, Loss: 0.0050 \n",
      " Epoch: 8, iteration: 7496, Loss: 0.0045 \n",
      " Epoch: 9, iteration: 8433, Loss: 0.0025 \n",
      " Epoch: 10, iteration: 9370, Loss: 0.0034 \n",
      " Epoch: 11, iteration: 10307, Loss: 0.0036 \n",
      " Epoch: 12, iteration: 11244, Loss: 0.0036 \n",
      " Epoch: 13, iteration: 12181, Loss: 0.0035 \n",
      " Epoch: 14, iteration: 13118, Loss: 0.0033 \n",
      " Epoch: 15, iteration: 14055, Loss: 0.0032 \n",
      " Epoch: 16, iteration: 14992, Loss: 0.0031 \n",
      " Epoch: 17, iteration: 15929, Loss: 0.0029 \n",
      " Epoch: 18, iteration: 16866, Loss: 0.0029 \n",
      " Epoch: 19, iteration: 17803, Loss: 0.0028 \n",
      " Epoch: 20, iteration: 18740, Loss: 0.0027 \n",
      " Epoch: 21, iteration: 19677, Loss: 0.0027 \n",
      " Epoch: 22, iteration: 20614, Loss: 0.0027 \n",
      " Epoch: 23, iteration: 21551, Loss: 0.0027 \n",
      " Epoch: 24, iteration: 22488, Loss: 0.0027 \n",
      " Epoch: 25, iteration: 23425, Loss: 0.0027 \n",
      " Epoch: 26, iteration: 24362, Loss: 0.0027 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_of_iterations = 25000\n",
    "loss_list=[]\n",
    "i_epoch = 0\n",
    "for i_iter in range(no_of_iterations):\n",
    "    \n",
    "    ''''''\n",
    "    batch_elem_idx = i_iter%num_minibatches\n",
    "    x_batchinput = x_train[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size]\n",
    "    \n",
    "   # first hidden layer implementation\n",
    "    a1 =x_batchinput@W1\n",
    "  \n",
    "    # implement Relu layer\n",
    "    h1 =relu(a1)\n",
    "    #  implement  hidden layer\n",
    "    a2 = h1@W2\n",
    "    \n",
    "    # softmax layer\n",
    "    softmax_score = softmax(a2) #enusre you have implemented the softmax function defined above\n",
    "\n",
    "    neg_log_softmax_score = -np.log(softmax_score+0.00000001) # The small number is added to avoid 0 input to log function\n",
    "    \n",
    "    # Compute and print loss\n",
    "    if i_iter%num_minibatches == 0:\n",
    "        loss = np.mean(np.diag(np.take(neg_log_softmax_score, gt_indices[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size],\\\n",
    "                                       axis=1)))\n",
    "        print(\" Epoch: {:d}, iteration: {:d}, Loss: {:6.4f} \".format(i_epoch, i_iter, loss))\n",
    "        loss_list.append(loss)\n",
    "        i_epoch += 1\n",
    "        # Each 10th epoch reduce learning rate by a factor of 10\n",
    "        if i_epoch%10 == 0:\n",
    "            learning_rate /= 10.0\n",
    "     \n",
    "    \n",
    "    \n",
    "    gradsoft = softmax_score-y_train[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size]\n",
    "    \n",
    "    # gradient w.r.t W3\n",
    "    grad_W2 = np.transpose(h1)@gradsoft\n",
    "   \n",
    "    # gradient w.r.t h1\n",
    "    grad_h1 = gradsoft@np.transpose(W2)\n",
    "    \n",
    "    # gradient w.r.t a1\n",
    "    grad_a1 = grad_h1*grad_relu(a1)\n",
    "    \n",
    "    # gradient w.r.t W1\n",
    "    grad_W1 = x_batchinput.T@grad_a1\n",
    "    \n",
    "    ################################ Update Weights Block using SGD ####################################\n",
    "    W2 -= learning_rate * grad_W2\n",
    "    W1 -= learning_rate * grad_W1\n",
    "    ####################################################################################################\n",
    "    \n",
    "#plotting the loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(loss_list)\n",
    "plt.title('Loss vs epochs')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = 't10k-images-idx3-ubyte'\n",
    "arr2 = idx2numpy.convert_from_file(file2)\n",
    "file3 = 't10k-labels-idx1-ubyte'\n",
    "arr3 = idx2numpy.convert_from_file(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading the test data from data/X_test.npy and data/y_test.npy.'''\n",
    "x_test = arr2\n",
    "x_test = x_test.flatten().reshape(-1,28*28)\n",
    "x_test = x_test / 255.0\n",
    "y_test = arr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 97.87 %\n"
     ]
    }
   ],
   "source": [
    "batch_size_test = 100 # Deliberately taken 100 so that it divides the test data size\n",
    "num_minibatches = len(y_test)/batch_size_test\n",
    "test_correct = 0\n",
    "\n",
    "'''Only forward block code and compute softmax_score .'''\n",
    "for i_iter in range(int(num_minibatches)):\n",
    "    \n",
    "    '''Get one minibatch'''\n",
    "    batch_elem_idx = i_iter%num_minibatches\n",
    "    x_batchinput = x_test[i_iter*batch_size_test:(i_iter+1)*batch_size_test]\n",
    "    \n",
    "    ######### copy only the forward pass block of your code and pass the x_batchinput to it and compute softmax_score ##########\n",
    "    a1 =x_batchinput@W1\n",
    "  \n",
    "    # implement Relu layer\n",
    "    h1 =relu(a1)\n",
    "    #  implement 2 hidden layer\n",
    "    a2 = h1@W2\n",
    "   \n",
    "    # softmax layer\n",
    "    softmax_score = softmax(a2) #Implemented the softmax function defined above\n",
    "    \n",
    "    \n",
    "    y_batchinput = y_test[i_iter*batch_size_test:(i_iter+1)*batch_size_test]\n",
    "    \n",
    "    y_pred = np.argmax(softmax_score, axis=1)\n",
    "    num_correct_i_iter = np.sum(y_pred == y_batchinput)\n",
    "    test_correct += num_correct_i_iter\n",
    "print (\"Test accuracy is {:4.2f} %\".format(test_correct/len(y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_Hidden_MLP_New.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
